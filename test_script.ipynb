{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\anaconda3\\envs\\SFAI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os                       # Operating system functions\n",
    "import subprocess               # Subprocess management\n",
    "import random                   # Random number generation\n",
    "from tqdm import tqdm           # Progress bars\n",
    "\n",
    "# Data Manipulation and Visualization\n",
    "import json                     # JSON data manipulation\n",
    "import inspect                  # Inspection of live objects\n",
    "import pandas as pd              # Data manipulation using DataFrames\n",
    "import numpy as np               # Numerical operations\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import seaborn as sns            # Styling plots\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image            # Python Imaging Library for image processing\n",
    "\n",
    "# Model Libraries\n",
    "import timm                     # Used for pre-trained models such as EfficientNet, ViT\n",
    "\n",
    "# PyTorch\n",
    "import torch                    # PyTorch overall import\n",
    "import torch.optim as optim     # Optimization of model parameters\n",
    "import torch.nn as nn           # Specification of neural networks\n",
    "from torch.utils.data import Dataset, DataLoader  # Data loading utilities\n",
    "import torchvision.transforms as transforms      # Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (4) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ciel Sun\\Desktop\\EE 562 AI_For_Enginers\\tiny-imagenet\\test_script.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ciel%20Sun/Desktop/EE%20562%20AI_For_Enginers/tiny-imagenet/test_script.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ciel%20Sun/Desktop/EE%20562%20AI_For_Enginers/tiny-imagenet/test_script.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ciel%20Sun/Desktop/EE%20562%20AI_For_Enginers/tiny-imagenet/test_script.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ciel%20Sun/Desktop/EE%20562%20AI_For_Enginers/tiny-imagenet/test_script.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39;49msqueeze(), target_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ciel%20Sun/Desktop/EE%20562%20AI_For_Enginers/tiny-imagenet/test_script.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ciel%20Sun/Desktop/EE%20562%20AI_For_Enginers/tiny-imagenet/test_script.ipynb#W1sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\SFAI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\SFAI\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\SFAI\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "# Define the Transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(2, 0, 1)  # Permute to (sequence_length, batch_size, input_size)\n",
    "        x = self.transformer(x, x)\n",
    "        x = x.permute(1, 2, 0)  # Permute back to (batch_size, input_size, sequence_length)\n",
    "        # x = x.mean(dim=1)  # Take the mean along the batch dimension (second dimension)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Set the input size, hidden size, number of layers, number of heads, and output size\n",
    "input_size = 1536\n",
    "hidden_size = 4\n",
    "num_layers = 8\n",
    "num_heads = 4\n",
    "output_size = 10  # Adjust as needed\n",
    "\n",
    "# Create an instance of the TransformerModel\n",
    "model = TransformerModel(input_size, hidden_size, num_layers, num_heads, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example input data with shape (batch_size, input_size, sequence_length)\n",
    "input_data = torch.randn(32, 2*2, input_size)\n",
    "\n",
    "# Example target data with shape (batch_size,)\n",
    "target_data = torch.randint(0, 2, (32, output_size))\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(input_data)\n",
    "    loss = criterion(outputs.squeeze(), target_data)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss for monitoring\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 1536])\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0794, -0.3366, -0.3976,  ...,  0.2945,  1.1435,  1.6424],\n",
      "         [ 0.4907, -0.0594, -0.2210,  ..., -0.0563,  0.9765,  0.8920],\n",
      "         [ 0.0992, -0.2409,  0.9599,  ...,  0.0962, -0.2762, -0.3120],\n",
      "         [ 0.4419,  0.0579,  0.8107,  ..., -0.0055, -0.1924, -0.3209]],\n",
      "\n",
      "        [[ 0.2797, -0.2210, -0.5159,  ...,  0.1250,  1.2915,  1.5387],\n",
      "         [ 0.2443, -0.2015, -0.0981,  ...,  0.1488,  0.8222,  1.0467],\n",
      "         [ 0.3390, -0.0454,  0.8310,  ...,  0.0260, -0.1910, -0.2933],\n",
      "         [ 0.2481, -0.1114,  0.9351,  ...,  0.0288, -0.2710, -0.3913]],\n",
      "\n",
      "        [[ 0.2268, -0.2149, -0.4845,  ...,  0.2332,  1.2156,  1.6483],\n",
      "         [ 0.3032, -0.2170, -0.1152,  ...,  0.0148,  0.8943,  0.8828],\n",
      "         [ 0.3992, -0.0163,  0.8329,  ..., -0.0085, -0.1990, -0.3624],\n",
      "         [ 0.1815, -0.1311,  0.9190,  ...,  0.0895, -0.2594, -0.2670]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1542, -0.3247, -0.4799,  ...,  0.2060,  1.2558,  1.6114],\n",
      "         [ 0.4325, -0.0451, -0.1532,  ...,  0.0289,  0.8763,  0.9414],\n",
      "         [ 0.2471, -0.1295,  0.8814,  ...,  0.0504, -0.2237, -0.3098],\n",
      "         [ 0.2772, -0.0801,  0.9039,  ...,  0.0436, -0.2568, -0.3416]],\n",
      "\n",
      "        [[ 0.2176, -0.2864, -0.4253,  ...,  0.2074,  1.1654,  1.5083],\n",
      "         [ 0.3675, -0.0783, -0.2295,  ...,  0.0136,  1.0004,  1.0649],\n",
      "         [ 0.2452, -0.1228,  0.8252,  ...,  0.0444, -0.1554, -0.2346],\n",
      "         [ 0.2808, -0.0919,  0.9821,  ...,  0.0635, -0.3593, -0.4379]],\n",
      "\n",
      "        [[ 0.1466, -0.3254, -0.4162,  ...,  0.2274,  1.1743,  1.5526],\n",
      "         [ 0.4297, -0.0548, -0.2331,  ...,  0.0049,  0.9819,  1.0217],\n",
      "         [ 0.2875, -0.0848,  0.8325,  ...,  0.0560, -0.1886, -0.2468],\n",
      "         [ 0.2470, -0.1146,  0.9692,  ...,  0.0406, -0.3163, -0.4267]]],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(input_data)\n",
    "outputs = outputs.squeeze()\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 0, 1, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 1, 1, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 1, 1, 0, 0, 1, 1],\n",
      "        [1, 0, 1, 1, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 1, 1, 0, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 1, 0, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 1, 0, 0, 1],\n",
      "        [1, 0, 0, 1, 0, 1, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1, 0, 0, 1, 1, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
      "        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
